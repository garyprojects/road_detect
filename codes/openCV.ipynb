{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openCV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Download course materials**"
      ],
      "metadata": {
        "id": "m5kgIeFHV8Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the tutorial materials\n",
        "!gdown --id '1QPPW3dEwVO0wN8aOCpwUQWIzhIxZpHF3' -O dataset.zip\n",
        "!unzip -q dataset.zip"
      ],
      "metadata": {
        "id": "Kf_6QQ36Tepc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import required libraries**"
      ],
      "metadata": {
        "id": "Mc7igjXoWA4i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWBj1-zTupjC"
      },
      "outputs": [],
      "source": [
        "# Import the required library\n",
        "import cv2 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # Display image by matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read and write of image**"
      ],
      "metadata": {
        "id": "Ibmtu_kjWIr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "original_image = cv2.imread('/content/Lesson1_materials/sample_Img1.jpg')\n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()\n",
        "\n",
        "# Using openCV to show image\n",
        "from google.colab.patches import cv2_imshow # Display image by OpenCV\n",
        "cv2_imshow(original_image)\n",
        "\n",
        "# Change it to grey scale\n",
        "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)  \n",
        "\n",
        "# Save the output image\n",
        "cv2.imwrite('output.jpg', gray_image)    "
      ],
      "metadata": {
        "id": "LU-0lJSpSF8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic operations of image processing**"
      ],
      "metadata": {
        "id": "xui78s6eWNW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "original_image = cv2.imread('/content/Lesson1_materials/sample_Img1.jpg')\n",
        "\n",
        "# Change it to grey scale\n",
        "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)  \n",
        "\n",
        "# Resize\n",
        "resizedImg = cv2.resize(gray_image, (400, 400), interpolation = cv2.INTER_CUBIC) \n",
        "\n",
        "# Blur\n",
        "# Convert the photo to gray scale，using Gaussian Blurring to remove noise\n",
        "GausBlur = cv2.GaussianBlur(resizedImg, (5, 5), 0)\n",
        "\n",
        "# Binary Image\n",
        "# If greater than T, set it to maximum, else 0\n",
        "(T, thresh) = cv2.threshold(GausBlur, 100, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iMarI-jbVRjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding lines and test**"
      ],
      "metadata": {
        "id": "azZaNRAAXuJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "original_image = cv2.imread('/content/Lesson1_materials/sample_Img1.jpg')\n",
        "\n",
        "# Adding lines and circles\n",
        "cv2.line(original_image, (0, 0), (255, 255), (0, 0, 255), 5)\n",
        "cv2.rectangle(original_image, (20, 60), (120, 160), (0, 255, 0), 2)\n",
        "cv2.circle(original_image, (90, 210), 30, (0, 255, 255), 3)\n",
        "# Adding text\n",
        "text = 'Hello world!'\n",
        "cv2.putText(original_image, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)  \n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zWp87yt9XdPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cropping of images**"
      ],
      "metadata": {
        "id": "kiYrZEuEYD8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "original_image = cv2.imread('/content/Lesson1_materials/sample_Img1.jpg')\n",
        "\n",
        "#Crop the photo, format–> Y1: Y2 X1: X2 \n",
        "cropped = original_image[0: 500, 0: 300]\n",
        "\n",
        "RGB_img1 = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img1)\n",
        "plt.show()\n",
        "\n",
        "RGB_img2 = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img2)\n",
        "plt.show()\n",
        "\n",
        "imgTest = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY) \n",
        "imgTestBlur = cv2.GaussianBlur(imgTest, (11, 11), 0)\n",
        "\n",
        "(T, thresh) = cv2.threshold(imgTestBlur, 150, 255, cv2.THRESH_BINARY)\t\n",
        "\n",
        "RGB_img3 = cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tHOUJN0IwpqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edges dectection and contour**"
      ],
      "metadata": {
        "id": "b_JjYC9aYaQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "original_image = cv2.imread('/content/Lesson1_materials/sample_Img1.jpg')\n",
        "gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY) \n",
        "img = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "canny = cv2.Canny(img, 30, 100)\n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(canny, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aKVCy09WYZ84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "original_image = cv2.imread('/content/Lesson1_materials/sample_Img1.jpg')\n",
        "imageCopy = original_image.copy()\n",
        "\n",
        "gray = cv2.cvtColor(imageCopy, cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "# Binary Image\n",
        "ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Calculate the contours\n",
        "contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cv2.drawContours(imageCopy, contours, -1, (0, 0, 255), 3)\n",
        "\n",
        "# You can base on the contours to continue for other post-processing decision\n",
        "#print(len(contours))\n",
        "#print(cv2.contourArea(contours[200]))\n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(imageCopy, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mHexxnxCY21l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some applications of using contours**"
      ],
      "metadata": {
        "id": "rxyJ7lTKfFBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('/content/Lesson1_materials/pattern.png')\n",
        "\n",
        "img_resized = cv2.resize(img, None,fx=0.8, fy=0.8, interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "imgGrayscale = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)                 # grayscale\n",
        "\n",
        "imgBlurred = cv2.GaussianBlur(imgGrayscale, (5, 5), 0)                       # blur\n",
        "\n",
        "ret, binary = cv2.threshold(imgBlurred, 230, 255, cv2.THRESH_BINARY)   \n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(binary, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   \n",
        "\n",
        "# Numbers of contours in the image\n",
        "print (\"Total Numbers of contours:\", str(len(contours)), end=\"\\n\\n\")\n",
        "\n",
        "index = 0\n",
        "\n",
        "for cnt in contours:\n",
        "    # 0.01: very high precision\n",
        "    approxVertex = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
        "\n",
        "    if len(approxVertex)==3:\n",
        "\n",
        "        cv2.drawContours(img_resized, [approxVertex], -1, (0, 0, 255), 3)\n",
        "\n",
        "        index = index + 1\n",
        "\n",
        "        print (\"There are \" + str(len(cnt)) + \" points in contour\", index)\n",
        "        print (\"There are \" + str(len(approxVertex)) + \" vertics in contour\", index)\n",
        "\n",
        "        area = cv2.contourArea(cnt)\n",
        "        print (\"The area is: \", area, \" in contour\", end=\"\\n\\n\")\n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kheb1V1jfDZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2a – Features extraction**"
      ],
      "metadata": {
        "id": "YDrXqpGogB2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Read the sample image and produce the features as shown in the handout\n",
        "'''"
      ],
      "metadata": {
        "id": "oUR52MYTgFeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2b – Face detection**"
      ],
      "metadata": {
        "id": "y6Smb3LFg8_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Read the test image and detect the faces by Haar features\n",
        "'''\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Load the cascade\n",
        "face_cascade = cv2.CascadeClassifier('/content/Lesson1_materials/haarcascade_frontalface_default.xml')\n",
        "# Read the input image\n",
        "img = cv2.imread('/content/Lesson1_materials/testImg.jpg')\n",
        "# Convert into grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "# Detect faces\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "# Draw rectangle around the faces\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "# Show the image\n",
        "RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(RGB_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CY5ZbTu8hArS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}